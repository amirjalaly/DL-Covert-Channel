{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Wu1otSUEUPBa"},"outputs":[],"source":["# example of a dcgan on cifar10\n","from numpy import expand_dims\n","from numpy import zeros\n","from numpy import ones\n","from numpy import vstack\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras.datasets.cifar10 import load_data\n","from tensorflow.keras.optimizers import Adam\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import MaxPooling2D\n","from keras.layers import LeakyReLU\n","from keras.layers import Dropout\n","from matplotlib import pyplot\n","from keras.models import load_model\n","import numpy as npu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J6_tmYlqUhky"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import tensorflow as tf\n","import cv2\n","import random\n","from tensorflow import keras\n","from keras.layers import Dense, Input, InputLayer, Flatten\n","from keras.models import Sequential, Model\n","from  matplotlib import pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_8N_IOSbUkoF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653120042268,"user_tz":-270,"elapsed":39569,"user":{"displayName":"Hora Pishbin","userId":"08979081459506148624"}},"outputId":"904c83f3-27a8-487a-f0e0-dd4c0c06cf55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8908,"status":"ok","timestamp":1653120051146,"user":{"displayName":"Hora Pishbin","userId":"08979081459506148624"},"user_tz":-270},"id":"17NM1N7-UpTX","outputId":"0b45e52e-89e4-4fad-dd8b-a26273989d95"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.95.130.122:8470\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.95.130.122:8470\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["Running on TPU  ['10.95.130.122:8470']\n","Number of accelerators:  8\n"]}],"source":["import tensorflow as tf\n","\n","try:\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n","except ValueError: # If TPU not found\n","  tpu = None\n","\n","# Select appropriate distribution strategy\n","if tpu:\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n","else:\n","  tpu_strategy = tf.distribute.get_strategy() # Default strategy that works on CPU and single GPU\n","  print('Running on CPU instead')\n","print(\"Number of accelerators: \", tpu_strategy.num_replicas_in_sync)  "]},{"cell_type":"markdown","source":["# pre-trained Isolated model (80,80,3) images\n","\n","weights of model are from InceptionV3 pre-trained model\n"],"metadata":{"id":"Vkqb3yOILxfV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SChykaeTqSKI"},"outputs":[],"source":["model_path = \"/content/drive/MyDrive/\"\n","with tpu_strategy.scope():\n","    isolated_model = tf.keras.models.load_model(model_path+\"InceptionV3_isolated_model_stanford_dogs_80x80x3.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHdtNP3yU6Du"},"outputs":[],"source":["IMG_HEIGHT=80\n","IMG_WIDTH=80"]},{"cell_type":"markdown","source":["# **Load The Stanford Dogs Dataset**\n","The Stanford Dogs Dataset contains images of 120 breeds of dogs from around the world. This dataset has been built using images and annotation from ImageNet for the task of fine-grained image categorization.\n","Contents of the dataset:\n","\n","Number of categories: 120\n","Number of images: 20,580\n","Annotations: Class labels, Bounding boxes\n","\n","The dataset can be downloaded from http://vision.stanford.edu/aditya86/ImageNetDogs/."],"metadata":{"id":"I4OdXS9AJUWc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"I8uYKnsVU67d"},"outputs":[],"source":["def create_dataset(dataset_folder):  \n","    img_data_array=[]\n","    class_name=[]\n","   \n","    for dir1 in os.listdir(dataset_folder):\n","        print(dir1)\n","        for file in os.listdir(os.path.join(dataset_folder, dir1)):\n","       \n","            image_path= os.path.join(dataset_folder, dir1,  file)\n","            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n","            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n","            image=np.array(image)\n","            image = image.astype('float32')\n","            image = (image-127.5) / 127.5 \n","            img_data_array.append(image)\n","            class_name.append(dir1)\n","    return img_data_array, class_name"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8BGtt_puVAe_","outputId":"1914c480-0435-4afd-9131-172c6b92f44f","executionInfo":{"status":"ok","timestamp":1653120417872,"user_tz":-270,"elapsed":327875,"user":{"displayName":"Hora Pishbin","userId":"08979081459506148624"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["n02088238-basset\n","n02085782-Japanese_spaniel\n","n02086910-papillon\n","n02085620-Chihuahua\n","n02088094-Afghan_hound\n","n02087046-toy_terrier\n","n02086240-Shih-Tzu\n","n02087394-Rhodesian_ridgeback\n","n02086646-Blenheim_spaniel\n","n02086079-Pekinese\n","n02085936-Maltese_dog\n","n02088364-beagle\n","n02088632-bluetick\n","n02089078-black-and-tan_coonhound\n","n02089867-Walker_hound\n","n02090379-redbone\n","n02090622-borzoi\n","n02091032-Italian_greyhound\n","n02091134-whippet\n","n02091467-Norwegian_elkhound\n","n02091831-Saluki\n","n02092339-Weimaraner\n","n02093256-Staffordshire_bullterrier\n","n02093428-American_Staffordshire_terrier\n","n02093647-Bedlington_terrier\n","n02093754-Border_terrier\n","n02093991-Irish_terrier\n","n02094258-Norwich_terrier\n","n02094433-Yorkshire_terrier\n","n02095314-wire-haired_fox_terrier\n","n02095570-Lakeland_terrier\n","n02095889-Sealyham_terrier\n","n02096051-Airedale\n","n02096177-cairn\n","n02096437-Dandie_Dinmont\n","n02096585-Boston_bull\n","n02097047-miniature_schnauzer\n","n02097130-giant_schnauzer\n","n02097298-Scotch_terrier\n","n02097474-Tibetan_terrier\n","n02097658-silky_terrier\n","n02098105-soft-coated_wheaten_terrier\n","n02098286-West_Highland_white_terrier\n","n02098413-Lhasa\n","n02099267-flat-coated_retriever\n","n02099429-curly-coated_retriever\n","n02099601-golden_retriever\n","n02099712-Labrador_retriever\n","n02099849-Chesapeake_Bay_retriever\n","n02100236-German_short-haired_pointer\n","n02100583-vizsla\n","n02100735-English_setter\n","n02100877-Irish_setter\n","n02101006-Gordon_setter\n","n02101388-Brittany_spaniel\n","n02101556-clumber\n","n02102040-English_springer\n","n02102177-Welsh_springer_spaniel\n","n02102318-cocker_spaniel\n","n02104029-kuvasz\n","n02104365-schipperke\n","n02105056-groenendael\n","n02105251-briard\n","n02105412-kelpie\n","n02105641-Old_English_sheepdog\n","n02106030-collie\n","n02106166-Border_collie\n","n02106550-Rottweiler\n","n02106662-German_shepherd\n","n02107312-miniature_pinscher\n","n02107574-Greater_Swiss_Mountain_dog\n","n02107683-Bernese_mountain_dog\n","n02107908-Appenzeller\n","n02108089-boxer\n","n02108422-bull_mastiff\n","n02108551-Tibetan_mastiff\n","n02109525-Saint_Bernard\n","n02109961-Eskimo_dog\n","n02110063-malamute\n","n02110185-Siberian_husky\n","n02110958-pug\n","n02111500-Great_Pyrenees\n","n02112018-Pomeranian\n","n02112137-chow\n","n02112350-keeshond\n","n02112706-Brabancon_griffon\n","n02113023-Pembroke\n","n02113186-Cardigan\n","n02113624-toy_poodle\n","n02113712-miniature_poodle\n","n02113799-standard_poodle\n","n02113978-Mexican_hairless\n","n02115641-dingo\n","n02088466-bloodhound\n","n02090721-Irish_wolfhound\n","n02091244-Ibizan_hound\n","n02092002-Scottish_deerhound\n","n02094114-Norfolk_terrier\n","n02093859-Kerry_blue_terrier\n","n02096294-Australian_terrier\n","n02097209-standard_schnauzer\n","n02102480-Sussex_spaniel\n","n02102973-Irish_water_spaniel\n","n02105162-malinois\n","n02105505-komondor\n","n02106382-Bouvier_des_Flandres\n","n02107142-Doberman\n","n02108000-EntleBucher\n","n02109047-Great_Dane\n","n02110806-basenji\n","n02111129-Leonberg\n","n02110627-affenpinscher\n","n02111889-Samoyed\n","n02111277-Newfoundland\n","n02115913-dhole\n","n02116738-African_hunting_dog\n","n02089973-English_foxhound\n","n02091635-otterhound\n","n02105855-Shetland_sheepdog\n","n02108915-French_bulldog\n"]}],"source":["#load data\n","with tpu_strategy.scope():\n","  dataset_folder=r'/content/drive/MyDrive/Stanford_Dogs_dataset/Images/'\n","  x_train, y_train = create_dataset(dataset_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1262,"status":"ok","timestamp":1653120419118,"user":{"displayName":"Hora Pishbin","userId":"08979081459506148624"},"user_tz":-270},"id":"EoZ1RCUuVB68","outputId":"fe8ae5b6-4a8a-4892-df37-b05088562775"},"outputs":[{"output_type":"stream","name":"stdout","text":["(20580, 80, 80, 3)\n"]}],"source":["x_train = np.asarray(x_train)\n","print(x_train.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z462IL-xq87-"},"outputs":[],"source":["dataset=x_train"]},{"cell_type":"markdown","metadata":{"id":"Lch99foEFGwT"},"source":["# define global parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f8DwyvNWPdBo"},"outputs":[],"source":["im_model = tf.keras.Model(inputs=isolated_model.input,\n","                                       outputs=isolated_model.get_layer(index=-2).output)\n","o=im_model(dataset)\n","output_dim = o.shape[1]\n","\n","TARGET_INDEX1 = 0\n","TARGET_INDEX2 = 1\n","mask = np.zeros(output_dim)\n","mask[TARGET_INDEX1] = 1\n","mask[TARGET_INDEX2] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3gx3xuCyxuM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653120450641,"user_tz":-270,"elapsed":87,"user":{"displayName":"Hora Pishbin","userId":"08979081459506148624"}},"outputId":"6cc8ae0f-5236-4ed8-bdd5-326f53795b37"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([20580, 2048])"]},"metadata":{},"execution_count":12}],"source":["o.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HRviwLcvzLdi"},"outputs":[],"source":["_max=tf.reduce_max(o, axis=0)"]},{"cell_type":"markdown","metadata":{"id":"iKAsA2HBMYZn"},"source":["# Discriminator defintion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxo7vQg2VSC8"},"outputs":[],"source":["# define the standalone discriminator model\n","def define_discriminator(in_shape=(IMG_HEIGHT,IMG_WIDTH,3)):\n","\tmodel = Sequential()\n","\t# normal\n","\tmodel.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Dropout(0.2))\n","\t# downsample\n","\tmodel.add(Conv2D(64, (3,3), strides=2, padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Dropout(0.2))\n","\t# downsample\n","\tmodel.add(Conv2D(128, (3,3), strides=2, padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Dropout(0.2))\n","\t# downsample\n","\tmodel.add(Conv2D(128, (3,3), strides=2, padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Dropout(0.2))\n","\tmodel.add(Conv2D(256, (3,3), strides=2, padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Dropout(0.2))\n","\t# classifier\n","\tmodel.add(Flatten())\n","\tmodel.add(Dense(1, activation='sigmoid'))\n","\t# compile model\n","\topt = Adam(learning_rate=0.0001, beta_1=0.5)\n","\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\treturn model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":91,"status":"ok","timestamp":1652179403725,"user":{"displayName":"Hora Pishbin","userId":"08979081459506148624"},"user_tz":-270},"id":"v71lHq9i1rDK","outputId":"0730e1f3-6a73-4a6c-d590-593df8683137"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 80, 80, 64)        1792      \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 80, 80, 64)        0         \n","                                                                 \n"," dropout (Dropout)           (None, 80, 80, 64)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 40, 40, 64)        36928     \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 40, 40, 64)        0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 40, 40, 64)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 20, 20, 128)       73856     \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 20, 20, 128)       0         \n","                                                                 \n"," dropout_2 (Dropout)         (None, 20, 20, 128)       0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 10, 10, 128)       147584    \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 10, 10, 128)       0         \n","                                                                 \n"," dropout_3 (Dropout)         (None, 10, 10, 128)       0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 5, 5, 256)         295168    \n","                                                                 \n"," leaky_re_lu_4 (LeakyReLU)   (None, 5, 5, 256)         0         \n","                                                                 \n"," dropout_4 (Dropout)         (None, 5, 5, 256)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 6400)              0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 6401      \n","                                                                 \n","=================================================================\n","Total params: 561,729\n","Trainable params: 561,729\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["d= define_discriminator()\n","d.summary()"]},{"cell_type":"markdown","metadata":{"id":"ar0rYHWOJaFW"},"source":["# generator defintion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iXh2jvdGVTmZ"},"outputs":[],"source":["# define the standalone generator model\n","def define_generator(latent_dim):\n","\tmodel = Sequential()\n","\t# foundation for 3x3 image\n","\tn_nodes = 256 * 5 * 5\n","\tmodel.add(Dense(n_nodes, input_dim=latent_dim+2))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Reshape((5, 5, 256)))\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=2, padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=2, padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=2, padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=2, padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\n","\tmodel.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n","\treturn model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":822,"status":"ok","timestamp":1652179404497,"user":{"displayName":"Hora Pishbin","userId":"08979081459506148624"},"user_tz":-270},"id":"jIGYSNyI1zxv","outputId":"1724e816-726c-413f-9cfa-54a1cd0bdd2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1 (Dense)             (None, 6400)              83200     \n","                                                                 \n"," leaky_re_lu_5 (LeakyReLU)   (None, 6400)              0         \n","                                                                 \n"," reshape (Reshape)           (None, 5, 5, 256)         0         \n","                                                                 \n"," conv2d_transpose (Conv2DTra  (None, 10, 10, 128)      524416    \n"," nspose)                                                         \n","                                                                 \n"," leaky_re_lu_6 (LeakyReLU)   (None, 10, 10, 128)       0         \n","                                                                 \n"," conv2d_transpose_1 (Conv2DT  (None, 20, 20, 128)      262272    \n"," ranspose)                                                       \n","                                                                 \n"," leaky_re_lu_7 (LeakyReLU)   (None, 20, 20, 128)       0         \n","                                                                 \n"," conv2d_transpose_2 (Conv2DT  (None, 40, 40, 128)      262272    \n"," ranspose)                                                       \n","                                                                 \n"," leaky_re_lu_8 (LeakyReLU)   (None, 40, 40, 128)       0         \n","                                                                 \n"," conv2d_transpose_3 (Conv2DT  (None, 80, 80, 128)      262272    \n"," ranspose)                                                       \n","                                                                 \n"," leaky_re_lu_9 (LeakyReLU)   (None, 80, 80, 128)       0         \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 80, 80, 3)         3459      \n","                                                                 \n","=================================================================\n","Total params: 1,397,891\n","Trainable params: 1,397,891\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["g=define_generator(10)\n","g.summary()"]},{"cell_type":"markdown","metadata":{"id":"QNNxFteEJiMc"},"source":["# GAN defintion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jvuj6H5eVWR0"},"outputs":[],"source":["# define the combined generator and discriminator model, for updating the generator\n","def define_gan(g_model, d_model):\n","\t# make weights in the discriminator not trainable\n","\td_model.trainable = False\n","\t# connect them\n","\tmodel = Sequential()\n","\t# add generator\n","\tmodel.add(g_model)\n","\t# add the discriminator\n","\tmodel.add(d_model)\n","\t# compile model\n","\topt = Adam(learning_rate=0.0001, beta_1=0.5)\n","\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n","\treturn model"]},{"cell_type":"markdown","metadata":{"id":"xVOoY_1xCJ7g"},"source":["# some functions for generating real and fake samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIYlyuWKVY-o"},"outputs":[],"source":["# select real samples\n","def generate_real_samples(dataset, n_samples):\n","\t# choose random instances\n","\tix = randint(0, dataset.shape[0], n_samples)\n","\t# retrieve selected images\n","\tX = dataset[ix]\n","\t# generate 'real' class labels (1)\n","\ty = ones((n_samples, 1))\n","\treturn X, y\n"," \n","# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples):\n","\t# generate points in the latent space\n","\tx_input = randn(latent_dim * n_samples)\n","\t# reshape into a batch of inputs for the network\n","\tx_input = x_input.reshape(n_samples, latent_dim)\n","\treturn x_input\n"," \n","# use the generator to generate n fake examples, with class labels\n","def generate_fake_samples(g_model, latent_dim, n_samples, covert_msg):\n","\t# generate points in latent space\n","\tl_points = generate_latent_points(latent_dim, n_samples)\n","\tx_input = np.concatenate([covert_msg, l_points], axis=1)\n","\t# predict outputs\n","\tX = g_model.predict(x_input)\n","\t# create 'fake' class labels (0)\n","\ty = zeros((n_samples, 1))\n","\treturn X, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aa4sZtqfVk44"},"outputs":[],"source":["def generate_covert_samples(n_samples):\n","    covert = np.random.randint(2,size=n_samples)\n","    covert_msg = np.array([[c, int(not(c))] for c  in covert], dtype=np.float32)\n","    covert_output = np.zeros((covert.shape[0], output_dim))\n","    for i in range(covert.shape[0]):\n","      if (covert[i]==0):\n","        covert_output[i][TARGET_INDEX1]=60\n","      if (covert[i]==1):\n","        covert_output[i][TARGET_INDEX2]=60\n","    return covert_msg, covert_output"]},{"cell_type":"markdown","metadata":{"id":"utI9y4nzD0u7"},"source":["# a function for plots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CWOa2oIvVdU4"},"outputs":[],"source":["# plot the generated images\n","def create_plot(examples, n):\n","\t# plot images\n","\tfor i in range(n * n):\n","\t\t# define subplot\n","\t\tpyplot.subplot(n, n, 1 + i)\n","\t\t# turn off axis\n","\t\tpyplot.axis('off')\n","\t\t# plot raw pixel data\n","\t\tpyplot.imshow(examples[i, :, :])\n","\tpyplot.show()"]},{"cell_type":"markdown","metadata":{"id":"6OpSf8IWEON_"},"source":["# definition of custom loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-TM3udqU7Bm"},"outputs":[],"source":["BATCH_SIZE_PER_REPLICA = 16\n","GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * tpu_strategy.num_replicas_in_sync\n","with tpu_strategy.scope():\n","    # Set reduction to `none` so we can do the reduction afterwards and divide by\n","    # global batch size.\n","    mae = tf.keras.losses.MeanAbsoluteError(\n","          reduction=tf.keras.losses.Reduction.NONE)\n","    def Covert_customLoss(yTrue,yPred):\n","        per_example_loss = mae(yTrue,yPred*mask)\n","        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"0TkSCL6hC5d9"},"source":["# Covert model definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82e8lF3cVnSD"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","\n","def define_covert_model(i_model, g_model):\n","    i_model.trainable = False\n","    intermediate_layer_model = tf.keras.Model(inputs=i_model.input,\n","                                       outputs=i_model.get_layer(index=-2).output)\n","\n","    c_model = Sequential()\n","    c_model.add(g_model)\n","    c_model.add(intermediate_layer_model)\n","    opt = Adam(learning_rate=0.002)\n","    c_model.compile(loss=Covert_customLoss,\n","                    optimizer=opt)\n","    return c_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZyRiQ18hVxgX"},"outputs":[],"source":["def train_covert_model(_size):\n","  c_msg, c_out = generate_covert_samples(_size)\n","  l_points = generate_latent_points(latent_dim, _size)\n","  c_l = np.concatenate([c_msg, l_points], axis=1)   \n","  c_loss = c_model.fit(c_l,c_out,batch_size=32)\n","  return c_loss"]},{"cell_type":"markdown","metadata":{"id":"tDhY_gQyEb08"},"source":["# a function for discriminator evaluation, plot generated images, save generator model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EDz-_aiKVsZn"},"outputs":[],"source":["# evaluate the discriminator, plot generated images, save generator model\n","def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=150):\n","\tcovert = np.random.randint(2,size=n_samples)\n","\tcovert_msg = np.array([[c, int(not(c))] for c  in covert], dtype=np.float32)\n","\t# prepare real samples\n","\tX_real, y_real = generate_real_samples(dataset, n_samples)\n","\t# evaluate discriminator on real examples\n","\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n","\t# prepare fake examples\n","\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples, covert_msg)\n","\t# evaluate discriminator on fake examples\n","\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n","\t# summarize discriminator performance\n","\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))"]},{"cell_type":"markdown","source":["# some functions for saving generators and showing results"],"metadata":{"id":"JajhcRmvP6AV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3lExLO4SVuv1"},"outputs":[],"source":["def save_function(epoch):\n","\tfilename = \"covert_stanford_dogs_generator_model_%03d.h5\" % (epoch+1)\n","\tg_model.save(model_path + filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LA7hj9O5V0Ve"},"outputs":[],"source":["def show_GAN_images(epoch, n_batch):\n","  # load model\n","  filename = \"covert_stanford_dogs_generator_model_%03d.h5\" % (epoch+1)\n","  model = load_model(model_path + filename)\n","  # generate images\n","  latent_points = generate_latent_points(latent_dim, n_batch)\n","  c_msg, c_out = generate_covert_samples(n_batch)\n","  c_l = np.concatenate([c_msg, latent_points], axis=1)\n","  # generate images\n","  X = model.predict(c_l)\n","  # scale from [-1,1] to [0,1]\n","  X = (X + 1) / 2.0\n","  # plot the result\n","  create_plot(X, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q16TihsTV2qq"},"outputs":[],"source":["def show_covert_indexes(c_model):\n","  c_msg, c_out = generate_covert_samples(20)\n","  l_points = generate_latent_points(latent_dim, 20)\n","  c_l = np.concatenate([c_msg, l_points], axis=1)\n","  covert_out = c_model.predict(c_l)\n","  for k in range(20):\n","    print(c_msg[k], \"   \",\n","          covert_out[k][TARGET_INDEX1], \"   \",\n","          covert_out[k][TARGET_INDEX2], \"   \",\n","          )"]},{"cell_type":"markdown","source":["# Indicator function definition"],"metadata":{"id":"w7F0OEOQNbW4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQc91_sYRzoO"},"outputs":[],"source":["def indicator(c_msg, real_outputs):\n","  _size = c_msg.shape[0]\n","  y_pred=[None]*_size\n","  y_true=[None]*_size\n","  for i in range(_size):\n","\n","    if(all(c_msg[i]==[0,1])):\n","      y_true[i]=0\n","    elif(all(c_msg[i]==[1,0])):\n","      y_true[i]=1\n","    else:\n","      y_true[i]=2\n","\n","    ro1=real_outputs[i][TARGET_INDEX1]\n","    ro2=real_outputs[i][TARGET_INDEX2]\n","    if (abs(ro1)>5 and abs(ro2)<0.5):\n","      y_pred[i]=0\n","    elif (abs(ro1)<0.5 and abs(ro2)>5):\n","      y_pred[i]=1\n","    else:\n","      y_pred[i]=2\n","      \n","  return y_true,y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oc0v4AMTPUYY"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","\n","def show_indicator(c_model):\n","  c_msg, c_out = generate_covert_samples(1000)\n","  l_points = generate_latent_points(latent_dim, 1000)\n","  c_l = np.concatenate([c_msg, l_points], axis=1)\n","  covert_out = c_model.predict(c_l)\n","\n","  y_true, y_pred = indicator(c_msg, covert_out)\n","  print(confusion_matrix(y_true, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"A6R1_xljE2Sw"},"source":["# this function includes the training loops"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNyX9K0ueJtQ"},"outputs":[],"source":["# train the generator and discriminator\n","def train(c_model, g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128):\n","  bat_per_epo = int(dataset.shape[0] / n_batch)\n","  half_batch = int(n_batch / 2)\n","\t# manually enumerate epochs\n","  for i in range(n_epochs):\n","\t\t# enumerate batches over the training set\n","    d1=0\n","    d2=0\n","    g=0\n","    for j in range(bat_per_epo):\n","      c_msg, c_out = generate_covert_samples(n_batch)\n","\n","\t\t\t# get randomly selected 'real' samples\n","      X_real, y_real = generate_real_samples(dataset, half_batch)\n","      # update discriminator model weights\n","      d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n","      # generate 'fake' examples\n","      X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch, c_msg[:half_batch])\n","      # update discriminator model weights\n","      d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n","\n","      # prepare points in latent space as input for the generator\n","      l_gan = generate_latent_points(latent_dim, n_batch)\n","      X_gan = np.concatenate([c_msg, l_gan], axis=1)\n","      # create inverted labels for the fake samples\n","      y_gan = ones((n_batch, 1))\n","      # update the generator via the discriminator's error\n","      g_loss = gan_model.train_on_batch(X_gan, y_gan)\n","\n","      d1=d1+d_loss1\n","      d2=d2+d_loss2\n","      g=g+g_loss\n","\n","      # summarize loss on this batch\n","      if(j%40==0):\n","        print('>%d, %d/%d, d1=%.3f, d2=%.3f, g=%.3f' %(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n","    \n","    # train covert model using fit function\n","    _size=10000\n","    c_loss = train_covert_model(_size)\n","\n","    print('avg d1=%.3f, avg d2=%.3f, avg g=%.3f' %(d1/bat_per_epo, d2/bat_per_epo, g/bat_per_epo))\n","    summarize_performance(i, g_model, d_model, dataset, latent_dim)\n","\n","    if(i%5==0):\n","      save_function(i)\n","      show_GAN_images(i, n_batch)\n","      show_covert_indexes(c_model)\n","      show_indicator(c_model)"]},{"cell_type":"markdown","metadata":{"id":"fGKIC3W9FyBB"},"source":["# now define the models and call train function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FgjIa-kKPfSK"},"outputs":[],"source":["model_path = \"/content/drive/MyDrive/covert_models/covert_stanford_dogs_generator/\"\n","\n","with tpu_strategy.scope():\n","  # size of the latent space\n","  latent_dim = 10\n","  d_model = define_discriminator()\n","  g_model = define_generator(latent_dim)\n","  gan_model = define_gan(g_model, d_model)\n","  c_model = define_covert_model(isolated_model, g_model)\n","  train(c_model, g_model, d_model, gan_model, dataset, latent_dim)"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[{"file_id":"1uqYZOy_QMGP6mtHvcO04wB6Bl75uNIyj","timestamp":1682857886552}],"authorship_tag":"ABX9TyPmzmhpS9NL6pLtJb28DJME"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}